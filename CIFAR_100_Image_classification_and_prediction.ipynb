{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yy9OErz22uwE"
      },
      "source": [
        "\n",
        "#**CIFAR-100 Image classsification and prediction ( using tensorflow)**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTSeLJ1tB-kn"
      },
      "source": [
        "## **Introduction**\n",
        "\n",
        "The CIFAR-100 dataset consists of 50,000 color training images and 10,000 testing images of size 32x32.The images are grouped under 100 labels (over 20 classes). The dataset can be used for deep learning and computer vision.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1lCJI6nGDld"
      },
      "source": [
        "Convolutional neural network (CNN) is a deep neural network used to analyze image data.A CNN can be build using teserflow to understand,classify and predict images of CIFAR-100 dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLh6lcGWtJse",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:32.147566Z",
          "iopub.execute_input": "2021-08-02T17:34:32.147906Z",
          "iopub.status.idle": "2021-08-02T17:34:32.155497Z",
          "shell.execute_reply.started": "2021-08-02T17:34:32.147875Z",
          "shell.execute_reply": "2021-08-02T17:34:32.154282Z"
        },
        "trusted": true
      },
      "source": [
        "# importing required libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import Input, Flatten, Dense, Dropout, Activation,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSqALTEfvzor",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:32.157170Z",
          "iopub.execute_input": "2021-08-02T17:34:32.157634Z",
          "iopub.status.idle": "2021-08-02T17:34:32.879286Z",
          "shell.execute_reply.started": "2021-08-02T17:34:32.157598Z",
          "shell.execute_reply": "2021-08-02T17:34:32.878384Z"
        },
        "trusted": true
      },
      "source": [
        "# loading dataset\n",
        "(x_train, y_train), (x_test,y_test) = datasets.cifar100.load_data()\n",
        "# loading the class labels\n",
        "labels =  ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUNcDQ_sv8Yi",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:32.881074Z",
          "iopub.execute_input": "2021-08-02T17:34:32.881462Z",
          "iopub.status.idle": "2021-08-02T17:34:32.886459Z",
          "shell.execute_reply.started": "2021-08-02T17:34:32.881422Z",
          "shell.execute_reply": "2021-08-02T17:34:32.885360Z"
        },
        "trusted": true,
        "outputId": "54b586e8-bf5e-4897-ba18-93701303b865"
      },
      "source": [
        "print(f'x_train ={x_train.shape} \\n y_train={y_train.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train =(50000, 32, 32, 3) \n",
            " y_train=(50000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNvBHFey9CNy",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:32.888018Z",
          "iopub.execute_input": "2021-08-02T17:34:32.888414Z",
          "iopub.status.idle": "2021-08-02T17:34:32.898888Z",
          "shell.execute_reply.started": "2021-08-02T17:34:32.888376Z",
          "shell.execute_reply": "2021-08-02T17:34:32.898065Z"
        },
        "trusted": true,
        "outputId": "62dddb02-8e82-4b43-aa94-624dd3e14567"
      },
      "source": [
        "print(f'x_text ={x_test.shape} \\n y_test={y_test.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_text =(10000, 32, 32, 3) \n",
            " y_test=(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wxf4Q6iuKZIH",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:32.901749Z",
          "iopub.execute_input": "2021-08-02T17:34:32.902016Z",
          "iopub.status.idle": "2021-08-02T17:34:32.910156Z",
          "shell.execute_reply.started": "2021-08-02T17:34:32.901992Z",
          "shell.execute_reply": "2021-08-02T17:34:32.909347Z"
        },
        "trusted": true,
        "outputId": "6dd29b14-7271-4547-86fe-338d532bf9ce"
      },
      "source": [
        "x_train[0,:,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkkDL37oI_HB"
      },
      "source": [
        "There are 50k training images and 10k test images of size, 32 pixels x 32 pixels, each image in 3 channels. The 3 channels represents the RGB values of each pixels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk1KKpntI4LT"
      },
      "source": [
        "##**Data visualization:**\n",
        "<p>To verify the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwbVMI5BJkvb",
        "cellView": "form",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:32.911792Z",
          "iopub.execute_input": "2021-08-02T17:34:32.912028Z",
          "iopub.status.idle": "2021-08-02T17:34:33.013559Z",
          "shell.execute_reply.started": "2021-08-02T17:34:32.912004Z",
          "shell.execute_reply": "2021-08-02T17:34:33.012502Z"
        },
        "trusted": true,
        "outputId": "756fd11d-dcbb-46d8-9c70-702d395ee7f8"
      },
      "source": [
        "#@title Sample Image\n",
        "# sample image\n",
        "index =np.random.randint(0,1000)\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(x_train[index])\n",
        "print(y_train[index])\n",
        "print(labels[int(y_train[index])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[98]\n",
            "woman\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 144x144 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFwiidTkKXWm"
      },
      "source": [
        "##**Data preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7Cb_aP_3HSD"
      },
      "source": [
        "A 4D array input is required by the CNN to perform image recognition and classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCOYwY1icnOZ"
      },
      "source": [
        "**Normalizing**:\n",
        "* Scaling the images to be within same range as the weights of the neural networks are initialized to very small numbers.\n",
        "* Normalization helps to converge models faster\n",
        "* pixel valies are scaled to range [0,1]\n",
        "* since the max value of CIFAR-100 image date is 255, we can normalize the data by dividing every number by 255\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRCyY2XfURoo",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:33.015148Z",
          "iopub.execute_input": "2021-08-02T17:34:33.015549Z",
          "iopub.status.idle": "2021-08-02T17:34:33.483578Z",
          "shell.execute_reply.started": "2021-08-02T17:34:33.015508Z",
          "shell.execute_reply": "2021-08-02T17:34:33.482657Z"
        },
        "trusted": true
      },
      "source": [
        "#4D array input for building the CNN model using Keras\n",
        "input_shape = (32, 32, 3)\n",
        "# to normalize data we divide every number to the max value which is 255.0, which also changes its type to float\n",
        "\n",
        "x_train =x_train/ 255.0\n",
        "x_test =x_test/ 255.0\n",
        "\n",
        "y_train = y_train.astype('float32')\n",
        "y_test = y_test.astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3HjUfjmaNJK"
      },
      "source": [
        "**Data augmentation:**\n",
        "<p>Another common pre-processing technique involves augmenting the existing data-set with perturbed versions of the existing images. Scaling, rotations and other affine transformations are typical. This is done to expose the neural network to a wide variety of variations. This makes it less likely that the neural network recognizes unwanted characteristics in the data-set.\n",
        "\n",
        "\n",
        "\n",
        "*   decreases the chance that the neural network recognizes unwanted charecteristics from data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MoqntptoI0x",
        "execution": {
          "iopub.status.busy": "2021-08-02T17:34:33.487565Z",
          "iopub.execute_input": "2021-08-02T17:34:33.487988Z",
          "iopub.status.idle": "2021-08-02T17:34:33.500200Z",
          "shell.execute_reply.started": "2021-08-02T17:34:33.487947Z",
          "shell.execute_reply": "2021-08-02T17:34:33.499225Z"
        },
        "trusted": true
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KcbUwwmcww_"
      },
      "source": [
        "## Building the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN3NJ7vb33uU"
      },
      "source": [
        "* CNN is configured to process input of shape (32,32,3) which is the format of CIFAR database, passing inpit chape to the first layer\n",
        "* Build a sequential model and convolution and max pooling layers are added to it. The hidden layers in a CNN are generally convolution and pooling(downsampling) layers.\n",
        "* In each convolution layer, we take a filter of a small size and move that filter across the image and perform convolution operations, which are the  element-wise matrix multiplication between the filter values and the pixels in the image and the resultant values are summed.\n",
        "*Batch normalization standardizes the inputs to a layer for each mini-batch; stabilizing and significantly reducing the number of training epochs needed to train a deep neural network\n",
        "* Dropout layers are added in between so that data is forced to find new path as the dropout randomly switches off some neurons in the network.This reduces overfitting\n",
        "* To complete the model, the last output of the convolutional base is fed into the dense layers to perform classfication.The output of conv layers needs to be flatten or unrol first since Dense layers take vectors as input while conv output is a tensor.\n",
        "* CIFAR - 100 has 100 output classes, final Dense layer with 100 outputs is used (decision making)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EC6sxcsay0f",
        "execution": {
          "iopub.status.busy": "2021-08-02T18:57:10.828988Z",
          "iopub.execute_input": "2021-08-02T18:57:10.829357Z",
          "iopub.status.idle": "2021-08-02T18:57:10.911100Z",
          "shell.execute_reply.started": "2021-08-02T18:57:10.829311Z",
          "shell.execute_reply": "2021-08-02T18:57:10.910243Z"
        },
        "trusted": true
      },
      "source": [
        "\n",
        "# initialize the model\n",
        "model = Sequential()\n",
        "# data augmentation commented as resourse limits in colab\n",
        "# model.add(data_augmentation)\n",
        "\n",
        "# Padding is added to preserve width and height.\n",
        "model.add(Conv2D(32, kernel_size=(5, 5), activation='relu', input_shape=input_shape,padding='same'))\n",
        "# Layer that normalizes its inputs\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2),strides=2))\n",
        "model.add(Dropout(.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding='same',activation = 'relu'))\n",
        "model.add(Conv2D(128, (3, 3), padding='same',activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',kernel_regularizer=regularizers.l2(0.00001),activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation = 'relu',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(256, (3, 3), padding='same',activation = 'relu',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation = 'relu',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation = 'relu',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',activation = 'relu',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(0.00001),activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Conv2D(512, (3, 3), padding='same',kernel_regularizer=regularizers.l2(0.00001),activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Conv2D(512, (3, 3),activation = 'relu', padding='same',kernel_regularizer=regularizers.l2(0.00001)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.5))\n",
        "# end of hidden layers\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,kernel_regularizer=regularizers.l2(0.00001),activation = 'relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# decision making layer\n",
        "model.add(Dense(100,activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iG-j_7-knEr"
      },
      "source": [
        "## Training and Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGDckAhkO6ET"
      },
      "source": [
        "<p>The model learns the dataset or is gradually optimized in this step of ML.The structure of the dataset is learned so that the model can make predicions on unseen data\n",
        "\n",
        "\n",
        "  * an epoch is one pass throught the dataset\n",
        "  * During each epoch,features(x) and labels(y) from dataset is taken.\n",
        "  * model variables are updated using an optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g15mAc1LQOw9",
        "execution": {
          "iopub.status.busy": "2021-08-02T18:57:22.956533Z",
          "iopub.execute_input": "2021-08-02T18:57:22.956845Z",
          "iopub.status.idle": "2021-08-02T19:34:47.570217Z",
          "shell.execute_reply.started": "2021-08-02T18:57:22.956816Z",
          "shell.execute_reply": "2021-08-02T19:34:47.569453Z"
        },
        "trusted": true,
        "outputId": "45f633fe-7007-4f5e-ccaa-fb775f5c9932"
      },
      "source": [
        "# To train a model with fit(), a loss function, an optimizer, and optionally, some metrics to monitor are needed to be specified\n",
        "# Compile the model\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "# fit data to the model\n",
        "model.fit(x=x_train, y=y_train, epochs=200,verbose=1,batch_size=256,\n",
        "           steps_per_epoch=x_train.shape[0] // 256,\n",
        "           validation_data=(x_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "195/195 [==============================] - 14s 60ms/step - loss: 5.0435 - accuracy: 0.0115 - val_loss: 4.6529 - val_accuracy: 0.0108\n",
            "Epoch 2/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 4.5478 - accuracy: 0.0197 - val_loss: 4.5786 - val_accuracy: 0.0176\n",
            "Epoch 3/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 4.3135 - accuracy: 0.0361 - val_loss: 4.4332 - val_accuracy: 0.0266\n",
            "Epoch 4/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 4.1980 - accuracy: 0.0458 - val_loss: 4.2596 - val_accuracy: 0.0520\n",
            "Epoch 5/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 4.0576 - accuracy: 0.0627 - val_loss: 4.1316 - val_accuracy: 0.0787\n",
            "Epoch 6/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 3.8998 - accuracy: 0.0838 - val_loss: 4.3583 - val_accuracy: 0.0965\n",
            "Epoch 7/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 3.7372 - accuracy: 0.1143 - val_loss: 3.9272 - val_accuracy: 0.1219\n",
            "Epoch 8/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 3.5282 - accuracy: 0.1400 - val_loss: 3.9634 - val_accuracy: 0.1326\n",
            "Epoch 9/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 3.3617 - accuracy: 0.1782 - val_loss: 3.2653 - val_accuracy: 0.2216\n",
            "Epoch 10/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 3.1642 - accuracy: 0.2115 - val_loss: 3.3967 - val_accuracy: 0.2070\n",
            "Epoch 11/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.9855 - accuracy: 0.2517 - val_loss: 3.1623 - val_accuracy: 0.2375\n",
            "Epoch 12/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.8453 - accuracy: 0.2835 - val_loss: 2.8923 - val_accuracy: 0.2875\n",
            "Epoch 13/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.6822 - accuracy: 0.3131 - val_loss: 2.8073 - val_accuracy: 0.3085\n",
            "Epoch 14/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.5803 - accuracy: 0.3372 - val_loss: 2.5102 - val_accuracy: 0.3675\n",
            "Epoch 15/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.5012 - accuracy: 0.3583 - val_loss: 2.4544 - val_accuracy: 0.3819\n",
            "Epoch 16/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.4337 - accuracy: 0.3805 - val_loss: 2.3754 - val_accuracy: 0.4059\n",
            "Epoch 17/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.6887 - accuracy: 0.3389 - val_loss: 2.4749 - val_accuracy: 0.3927\n",
            "Epoch 18/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.3860 - accuracy: 0.4021 - val_loss: 2.9107 - val_accuracy: 0.3372\n",
            "Epoch 19/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.4732 - accuracy: 0.3882 - val_loss: 2.6717 - val_accuracy: 0.3632\n",
            "Epoch 20/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.3673 - accuracy: 0.4106 - val_loss: 2.4217 - val_accuracy: 0.4145\n",
            "Epoch 21/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2724 - accuracy: 0.4344 - val_loss: 2.4358 - val_accuracy: 0.4178\n",
            "Epoch 22/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.4912 - accuracy: 0.3969 - val_loss: 2.3445 - val_accuracy: 0.4374\n",
            "Epoch 23/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2654 - accuracy: 0.4454 - val_loss: 2.1587 - val_accuracy: 0.4753\n",
            "Epoch 24/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.1931 - accuracy: 0.4641 - val_loss: 2.2140 - val_accuracy: 0.4810\n",
            "Epoch 25/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.1405 - accuracy: 0.4770 - val_loss: 2.5837 - val_accuracy: 0.4070\n",
            "Epoch 26/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2308 - accuracy: 0.4610 - val_loss: 2.1403 - val_accuracy: 0.4946\n",
            "Epoch 27/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.1010 - accuracy: 0.4971 - val_loss: 2.1096 - val_accuracy: 0.5061\n",
            "Epoch 28/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0151 - accuracy: 0.5211 - val_loss: 2.1051 - val_accuracy: 0.5122\n",
            "Epoch 29/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0187 - accuracy: 0.5243 - val_loss: 2.1311 - val_accuracy: 0.5130\n",
            "Epoch 30/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9801 - accuracy: 0.5281 - val_loss: 2.4937 - val_accuracy: 0.4424\n",
            "Epoch 31/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.1097 - accuracy: 0.5071 - val_loss: 2.1765 - val_accuracy: 0.5109\n",
            "Epoch 32/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9741 - accuracy: 0.5432 - val_loss: 2.2397 - val_accuracy: 0.5072\n",
            "Epoch 33/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9723 - accuracy: 0.5442 - val_loss: 2.1071 - val_accuracy: 0.5285\n",
            "Epoch 34/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9501 - accuracy: 0.5563 - val_loss: 2.6789 - val_accuracy: 0.4223\n",
            "Epoch 35/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2092 - accuracy: 0.5004 - val_loss: 2.2499 - val_accuracy: 0.5219\n",
            "Epoch 36/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0157 - accuracy: 0.5476 - val_loss: 2.3188 - val_accuracy: 0.4984\n",
            "Epoch 37/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2462 - accuracy: 0.5067 - val_loss: 3.9358 - val_accuracy: 0.2748\n",
            "Epoch 38/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.1966 - accuracy: 0.5154 - val_loss: 2.5682 - val_accuracy: 0.4590\n",
            "Epoch 39/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2319 - accuracy: 0.5139 - val_loss: 2.2190 - val_accuracy: 0.5246\n",
            "Epoch 40/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.6407 - accuracy: 0.4351 - val_loss: 3.4573 - val_accuracy: 0.3101\n",
            "Epoch 41/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.4942 - accuracy: 0.4600 - val_loss: 2.5798 - val_accuracy: 0.4489\n",
            "Epoch 42/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2114 - accuracy: 0.5261 - val_loss: 2.2961 - val_accuracy: 0.5147\n",
            "Epoch 43/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0809 - accuracy: 0.5528 - val_loss: 2.4419 - val_accuracy: 0.5008\n",
            "Epoch 44/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.0707 - accuracy: 0.5611 - val_loss: 2.3530 - val_accuracy: 0.5222\n",
            "Epoch 45/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.1053 - accuracy: 0.5533 - val_loss: 2.1992 - val_accuracy: 0.5499\n",
            "Epoch 46/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.9382 - accuracy: 0.5915 - val_loss: 2.2691 - val_accuracy: 0.5369\n",
            "Epoch 47/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.8378 - accuracy: 0.4159 - val_loss: 4.5811 - val_accuracy: 0.1499\n",
            "Epoch 48/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 3.2080 - accuracy: 0.3252 - val_loss: 2.8785 - val_accuracy: 0.3974\n",
            "Epoch 49/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.7558 - accuracy: 0.4161 - val_loss: 2.6308 - val_accuracy: 0.4544\n",
            "Epoch 50/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.5479 - accuracy: 0.4655 - val_loss: 2.4206 - val_accuracy: 0.5045\n",
            "Epoch 51/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.4308 - accuracy: 0.4925 - val_loss: 2.4735 - val_accuracy: 0.5029\n",
            "Epoch 52/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.3745 - accuracy: 0.5077 - val_loss: 3.2489 - val_accuracy: 0.3662\n",
            "Epoch 53/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.4138 - accuracy: 0.5053 - val_loss: 2.4563 - val_accuracy: 0.5088\n",
            "Epoch 54/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.2804 - accuracy: 0.5339 - val_loss: 2.4724 - val_accuracy: 0.5019\n",
            "Epoch 55/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.2953 - accuracy: 0.5283 - val_loss: 2.3763 - val_accuracy: 0.5313\n",
            "Epoch 56/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.1744 - accuracy: 0.5593 - val_loss: 2.2962 - val_accuracy: 0.5424\n",
            "Epoch 57/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.2329 - accuracy: 0.5512 - val_loss: 2.4203 - val_accuracy: 0.5275\n",
            "Epoch 58/200\n",
            "195/195 [==============================] - 11s 59ms/step - loss: 2.2183 - accuracy: 0.5505 - val_loss: 2.4514 - val_accuracy: 0.5185\n",
            "Epoch 59/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.1587 - accuracy: 0.5708 - val_loss: 2.2615 - val_accuracy: 0.5639\n",
            "Epoch 60/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.2910 - accuracy: 0.5433 - val_loss: 2.4785 - val_accuracy: 0.5149\n",
            "Epoch 61/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.2560 - accuracy: 0.5526 - val_loss: 2.3332 - val_accuracy: 0.5508\n",
            "Epoch 62/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.2050 - accuracy: 0.5669 - val_loss: 2.2989 - val_accuracy: 0.5651\n",
            "Epoch 63/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.1209 - accuracy: 0.5821 - val_loss: 2.2974 - val_accuracy: 0.5645\n",
            "Epoch 64/200\n",
            "195/195 [==============================] - 11s 59ms/step - loss: 2.0935 - accuracy: 0.5950 - val_loss: 2.5630 - val_accuracy: 0.5227\n",
            "Epoch 65/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.0793 - accuracy: 0.6017 - val_loss: 2.6004 - val_accuracy: 0.5215\n",
            "Epoch 66/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.0438 - accuracy: 0.6068 - val_loss: 2.5442 - val_accuracy: 0.5235\n",
            "Epoch 67/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 2.0466 - accuracy: 0.6113 - val_loss: 2.2713 - val_accuracy: 0.5739\n",
            "Epoch 68/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0145 - accuracy: 0.6203 - val_loss: 2.3249 - val_accuracy: 0.5777\n",
            "Epoch 69/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0695 - accuracy: 0.6073 - val_loss: 2.3236 - val_accuracy: 0.5804\n",
            "Epoch 70/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9813 - accuracy: 0.6328 - val_loss: 2.3111 - val_accuracy: 0.5792\n",
            "Epoch 71/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9387 - accuracy: 0.6398 - val_loss: 2.3042 - val_accuracy: 0.5893\n",
            "Epoch 72/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9465 - accuracy: 0.6421 - val_loss: 2.5184 - val_accuracy: 0.5424\n",
            "Epoch 73/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.1667 - accuracy: 0.5972 - val_loss: 2.3692 - val_accuracy: 0.5684\n",
            "Epoch 74/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0463 - accuracy: 0.6218 - val_loss: 2.3465 - val_accuracy: 0.5797\n",
            "Epoch 75/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9497 - accuracy: 0.6482 - val_loss: 2.5808 - val_accuracy: 0.5455\n",
            "Epoch 76/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9614 - accuracy: 0.6484 - val_loss: 2.3299 - val_accuracy: 0.5874\n",
            "Epoch 77/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.8581 - accuracy: 0.6732 - val_loss: 2.4673 - val_accuracy: 0.5664\n",
            "Epoch 78/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.8595 - accuracy: 0.6720 - val_loss: 2.3713 - val_accuracy: 0.5865\n",
            "Epoch 79/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8840 - accuracy: 0.6661 - val_loss: 2.3264 - val_accuracy: 0.5941\n",
            "Epoch 80/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.8688 - accuracy: 0.6746 - val_loss: 2.3493 - val_accuracy: 0.5971\n",
            "Epoch 81/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.8216 - accuracy: 0.6886 - val_loss: 2.4366 - val_accuracy: 0.5841\n",
            "Epoch 82/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7939 - accuracy: 0.6919 - val_loss: 2.4209 - val_accuracy: 0.5939\n",
            "Epoch 83/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7857 - accuracy: 0.6958 - val_loss: 2.3343 - val_accuracy: 0.6080\n",
            "Epoch 84/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7550 - accuracy: 0.7065 - val_loss: 2.5351 - val_accuracy: 0.5753\n",
            "Epoch 85/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.8215 - accuracy: 0.6912 - val_loss: 2.3943 - val_accuracy: 0.6011\n",
            "Epoch 86/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7555 - accuracy: 0.7076 - val_loss: 2.4444 - val_accuracy: 0.5971\n",
            "Epoch 87/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7754 - accuracy: 0.7025 - val_loss: 2.5670 - val_accuracy: 0.5658\n",
            "Epoch 88/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9244 - accuracy: 0.6729 - val_loss: 2.6136 - val_accuracy: 0.5458\n",
            "Epoch 89/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9758 - accuracy: 0.6636 - val_loss: 2.4895 - val_accuracy: 0.5797\n",
            "Epoch 90/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.8279 - accuracy: 0.6961 - val_loss: 2.4936 - val_accuracy: 0.5916\n",
            "Epoch 91/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7886 - accuracy: 0.7094 - val_loss: 2.8998 - val_accuracy: 0.5190\n",
            "Epoch 92/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8504 - accuracy: 0.6948 - val_loss: 2.6277 - val_accuracy: 0.5626\n",
            "Epoch 93/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7919 - accuracy: 0.7113 - val_loss: 2.5569 - val_accuracy: 0.5840\n",
            "Epoch 94/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8228 - accuracy: 0.7022 - val_loss: 2.4539 - val_accuracy: 0.6094\n",
            "Epoch 95/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8174 - accuracy: 0.7079 - val_loss: 2.5857 - val_accuracy: 0.5947\n",
            "Epoch 96/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8037 - accuracy: 0.7162 - val_loss: 2.5898 - val_accuracy: 0.5840\n",
            "Epoch 97/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8675 - accuracy: 0.7024 - val_loss: 2.5243 - val_accuracy: 0.5967\n",
            "Epoch 98/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7861 - accuracy: 0.7194 - val_loss: 2.5115 - val_accuracy: 0.5975\n",
            "Epoch 99/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8879 - accuracy: 0.6983 - val_loss: 2.5569 - val_accuracy: 0.5970\n",
            "Epoch 100/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7924 - accuracy: 0.7226 - val_loss: 2.5188 - val_accuracy: 0.5991\n",
            "Epoch 101/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8010 - accuracy: 0.7211 - val_loss: 2.5172 - val_accuracy: 0.6138\n",
            "Epoch 102/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.9768 - accuracy: 0.6825 - val_loss: 2.5247 - val_accuracy: 0.6065\n",
            "Epoch 103/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7282 - accuracy: 0.7400 - val_loss: 2.5189 - val_accuracy: 0.6115\n",
            "Epoch 104/200\n",
            "195/195 [==============================] - 11s 59ms/step - loss: 1.6954 - accuracy: 0.7475 - val_loss: 2.5761 - val_accuracy: 0.6091\n",
            "Epoch 105/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7063 - accuracy: 0.7527 - val_loss: 2.6381 - val_accuracy: 0.5803\n",
            "Epoch 106/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7777 - accuracy: 0.7342 - val_loss: 2.5335 - val_accuracy: 0.6081\n",
            "Epoch 107/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7609 - accuracy: 0.7391 - val_loss: 2.5849 - val_accuracy: 0.6067\n",
            "Epoch 108/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8500 - accuracy: 0.7211 - val_loss: 2.6369 - val_accuracy: 0.6013\n",
            "Epoch 109/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6991 - accuracy: 0.7567 - val_loss: 2.6253 - val_accuracy: 0.6007\n",
            "Epoch 110/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7330 - accuracy: 0.7523 - val_loss: 2.5471 - val_accuracy: 0.6122\n",
            "Epoch 111/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6673 - accuracy: 0.7646 - val_loss: 4.2739 - val_accuracy: 0.3806\n",
            "Epoch 112/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9598 - accuracy: 0.7035 - val_loss: 2.6382 - val_accuracy: 0.6004\n",
            "Epoch 113/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7891 - accuracy: 0.7414 - val_loss: 2.6198 - val_accuracy: 0.6011\n",
            "Epoch 114/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7431 - accuracy: 0.7542 - val_loss: 2.7041 - val_accuracy: 0.5927\n",
            "Epoch 115/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.9049 - accuracy: 0.7185 - val_loss: 2.6173 - val_accuracy: 0.6067\n",
            "Epoch 116/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7710 - accuracy: 0.7484 - val_loss: 2.6026 - val_accuracy: 0.6134\n",
            "Epoch 117/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7297 - accuracy: 0.7615 - val_loss: 2.6198 - val_accuracy: 0.6197\n",
            "Epoch 118/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7183 - accuracy: 0.7671 - val_loss: 2.7054 - val_accuracy: 0.6000\n",
            "Epoch 119/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6879 - accuracy: 0.7739 - val_loss: 2.7324 - val_accuracy: 0.5955\n",
            "Epoch 120/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6713 - accuracy: 0.7795 - val_loss: 2.7054 - val_accuracy: 0.6128\n",
            "Epoch 121/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6885 - accuracy: 0.7758 - val_loss: 2.6326 - val_accuracy: 0.6166\n",
            "Epoch 122/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6897 - accuracy: 0.7819 - val_loss: 2.6948 - val_accuracy: 0.6092\n",
            "Epoch 123/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7170 - accuracy: 0.7711 - val_loss: 2.6979 - val_accuracy: 0.6115\n",
            "Epoch 124/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6539 - accuracy: 0.7888 - val_loss: 2.7222 - val_accuracy: 0.6133\n",
            "Epoch 125/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6571 - accuracy: 0.7889 - val_loss: 2.6807 - val_accuracy: 0.6141\n",
            "Epoch 126/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6453 - accuracy: 0.7923 - val_loss: 3.2157 - val_accuracy: 0.5108\n",
            "Epoch 127/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 2.0237 - accuracy: 0.7024 - val_loss: 2.7427 - val_accuracy: 0.6000\n",
            "Epoch 128/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7217 - accuracy: 0.7761 - val_loss: 2.7411 - val_accuracy: 0.6087\n",
            "Epoch 129/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7768 - accuracy: 0.7664 - val_loss: 2.8113 - val_accuracy: 0.6046\n",
            "Epoch 130/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6909 - accuracy: 0.7889 - val_loss: 2.7322 - val_accuracy: 0.6129\n",
            "Epoch 131/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6957 - accuracy: 0.7867 - val_loss: 2.7698 - val_accuracy: 0.6242\n",
            "Epoch 132/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8056 - accuracy: 0.7632 - val_loss: 2.7900 - val_accuracy: 0.6088\n",
            "Epoch 133/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6726 - accuracy: 0.7973 - val_loss: 2.7469 - val_accuracy: 0.6181\n",
            "Epoch 134/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7048 - accuracy: 0.7909 - val_loss: 3.3193 - val_accuracy: 0.5025\n",
            "Epoch 135/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8835 - accuracy: 0.7483 - val_loss: 2.7310 - val_accuracy: 0.6168\n",
            "Epoch 136/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7212 - accuracy: 0.7888 - val_loss: 3.0119 - val_accuracy: 0.5860\n",
            "Epoch 137/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7660 - accuracy: 0.7761 - val_loss: 2.9559 - val_accuracy: 0.5930\n",
            "Epoch 138/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6481 - accuracy: 0.8080 - val_loss: 2.9321 - val_accuracy: 0.5925\n",
            "Epoch 139/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6838 - accuracy: 0.8007 - val_loss: 2.8397 - val_accuracy: 0.6114\n",
            "Epoch 140/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6958 - accuracy: 0.7984 - val_loss: 2.8359 - val_accuracy: 0.6085\n",
            "Epoch 141/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6821 - accuracy: 0.8036 - val_loss: 2.7802 - val_accuracy: 0.6227\n",
            "Epoch 142/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6382 - accuracy: 0.8119 - val_loss: 3.3433 - val_accuracy: 0.5428\n",
            "Epoch 143/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7158 - accuracy: 0.7943 - val_loss: 2.8867 - val_accuracy: 0.6103\n",
            "Epoch 144/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6775 - accuracy: 0.8039 - val_loss: 2.8449 - val_accuracy: 0.6135\n",
            "Epoch 145/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6693 - accuracy: 0.8073 - val_loss: 2.8390 - val_accuracy: 0.6280\n",
            "Epoch 146/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6030 - accuracy: 0.8263 - val_loss: 2.8058 - val_accuracy: 0.6314\n",
            "Epoch 147/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.5847 - accuracy: 0.8294 - val_loss: 3.1019 - val_accuracy: 0.5914\n",
            "Epoch 148/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6153 - accuracy: 0.8239 - val_loss: 2.9652 - val_accuracy: 0.6113\n",
            "Epoch 149/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6076 - accuracy: 0.8265 - val_loss: 2.8753 - val_accuracy: 0.6165\n",
            "Epoch 150/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6200 - accuracy: 0.8221 - val_loss: 2.9159 - val_accuracy: 0.6150\n",
            "Epoch 151/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.5761 - accuracy: 0.8344 - val_loss: 2.9363 - val_accuracy: 0.6122\n",
            "Epoch 152/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.5733 - accuracy: 0.8368 - val_loss: 2.9519 - val_accuracy: 0.6190\n",
            "Epoch 153/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6020 - accuracy: 0.8303 - val_loss: 2.8944 - val_accuracy: 0.6171\n",
            "Epoch 154/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6853 - accuracy: 0.8123 - val_loss: 2.8715 - val_accuracy: 0.6234\n",
            "Epoch 155/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.5923 - accuracy: 0.8333 - val_loss: 2.8358 - val_accuracy: 0.6253\n",
            "Epoch 156/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.5408 - accuracy: 0.8475 - val_loss: 3.1985 - val_accuracy: 0.5834\n",
            "Epoch 157/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.5978 - accuracy: 0.8334 - val_loss: 2.9806 - val_accuracy: 0.5880\n",
            "Epoch 158/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8675 - accuracy: 0.7719 - val_loss: 3.2809 - val_accuracy: 0.5045\n",
            "Epoch 159/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9275 - accuracy: 0.7542 - val_loss: 2.9029 - val_accuracy: 0.6074\n",
            "Epoch 160/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7368 - accuracy: 0.8044 - val_loss: 2.9201 - val_accuracy: 0.6103\n",
            "Epoch 161/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6690 - accuracy: 0.8202 - val_loss: 2.9372 - val_accuracy: 0.6183\n",
            "Epoch 162/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6228 - accuracy: 0.8300 - val_loss: 2.9206 - val_accuracy: 0.6119\n",
            "Epoch 163/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.5996 - accuracy: 0.8418 - val_loss: 2.9306 - val_accuracy: 0.6298\n",
            "Epoch 164/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6024 - accuracy: 0.8397 - val_loss: 3.1325 - val_accuracy: 0.5661\n",
            "Epoch 165/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7195 - accuracy: 0.8111 - val_loss: 3.9906 - val_accuracy: 0.4448\n",
            "Epoch 166/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9753 - accuracy: 0.7462 - val_loss: 3.8868 - val_accuracy: 0.4715\n",
            "Epoch 167/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7731 - accuracy: 0.8011 - val_loss: 2.9127 - val_accuracy: 0.6163\n",
            "Epoch 168/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7116 - accuracy: 0.8190 - val_loss: 2.9633 - val_accuracy: 0.6011\n",
            "Epoch 169/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6649 - accuracy: 0.8284 - val_loss: 2.9844 - val_accuracy: 0.6245\n",
            "Epoch 170/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6025 - accuracy: 0.8459 - val_loss: 3.6476 - val_accuracy: 0.4440\n",
            "Epoch 171/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.9779 - accuracy: 0.7525 - val_loss: 2.9842 - val_accuracy: 0.6225\n",
            "Epoch 172/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6587 - accuracy: 0.8358 - val_loss: 2.9184 - val_accuracy: 0.6245\n",
            "Epoch 173/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6145 - accuracy: 0.8469 - val_loss: 3.1571 - val_accuracy: 0.5933\n",
            "Epoch 174/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.8832 - accuracy: 0.7791 - val_loss: 2.9715 - val_accuracy: 0.5803\n",
            "Epoch 175/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8140 - accuracy: 0.7991 - val_loss: 3.0688 - val_accuracy: 0.6028\n",
            "Epoch 176/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7035 - accuracy: 0.8260 - val_loss: 3.0127 - val_accuracy: 0.6137\n",
            "Epoch 177/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.7941 - accuracy: 0.8088 - val_loss: 3.0408 - val_accuracy: 0.5781\n",
            "Epoch 178/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.9481 - accuracy: 0.7667 - val_loss: 2.9725 - val_accuracy: 0.6147\n",
            "Epoch 179/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7465 - accuracy: 0.8205 - val_loss: 2.9618 - val_accuracy: 0.6173\n",
            "Epoch 180/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6817 - accuracy: 0.8391 - val_loss: 2.9842 - val_accuracy: 0.6202\n",
            "Epoch 181/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6550 - accuracy: 0.8457 - val_loss: 3.1880 - val_accuracy: 0.5876\n",
            "Epoch 182/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7954 - accuracy: 0.8100 - val_loss: 2.9286 - val_accuracy: 0.6166\n",
            "Epoch 183/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7636 - accuracy: 0.8158 - val_loss: 2.9786 - val_accuracy: 0.6128\n",
            "Epoch 184/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.8096 - accuracy: 0.8091 - val_loss: 3.0487 - val_accuracy: 0.6115\n",
            "Epoch 185/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6752 - accuracy: 0.8428 - val_loss: 3.0378 - val_accuracy: 0.6160\n",
            "Epoch 186/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.7100 - accuracy: 0.8339 - val_loss: 3.0173 - val_accuracy: 0.6146\n",
            "Epoch 187/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6835 - accuracy: 0.8416 - val_loss: 3.0086 - val_accuracy: 0.6251\n",
            "Epoch 188/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6330 - accuracy: 0.8532 - val_loss: 3.5032 - val_accuracy: 0.5557\n",
            "Epoch 189/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6693 - accuracy: 0.8434 - val_loss: 3.1932 - val_accuracy: 0.5958\n",
            "Epoch 190/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6209 - accuracy: 0.8576 - val_loss: 3.0468 - val_accuracy: 0.6269\n",
            "Epoch 191/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6242 - accuracy: 0.8549 - val_loss: 3.0556 - val_accuracy: 0.6150\n",
            "Epoch 192/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6362 - accuracy: 0.8544 - val_loss: 3.0055 - val_accuracy: 0.6191\n",
            "Epoch 193/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.5935 - accuracy: 0.8640 - val_loss: 3.1850 - val_accuracy: 0.5939\n",
            "Epoch 194/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6453 - accuracy: 0.8480 - val_loss: 3.0532 - val_accuracy: 0.6217\n",
            "Epoch 195/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6127 - accuracy: 0.8564 - val_loss: 3.0546 - val_accuracy: 0.6119\n",
            "Epoch 196/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.5922 - accuracy: 0.8638 - val_loss: 3.1148 - val_accuracy: 0.5973\n",
            "Epoch 197/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6364 - accuracy: 0.8524 - val_loss: 3.0293 - val_accuracy: 0.6244\n",
            "Epoch 198/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.5699 - accuracy: 0.8710 - val_loss: 3.1673 - val_accuracy: 0.6128\n",
            "Epoch 199/200\n",
            "195/195 [==============================] - 11s 58ms/step - loss: 1.6284 - accuracy: 0.8564 - val_loss: 3.0602 - val_accuracy: 0.6228\n",
            "Epoch 200/200\n",
            "195/195 [==============================] - 11s 57ms/step - loss: 1.6040 - accuracy: 0.8653 - val_loss: 3.0150 - val_accuracy: 0.6290\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4ef8998d50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UbhQho0TU96"
      },
      "source": [
        "In evaluation, how effectively does the model makes predictions is determined.Test dataset is used for this.The model only evaluates a single epoch unlike training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OL0b-L2dcefL",
        "execution": {
          "iopub.status.busy": "2021-08-02T19:39:03.802801Z",
          "iopub.execute_input": "2021-08-02T19:39:03.803115Z",
          "iopub.status.idle": "2021-08-02T19:39:06.385961Z",
          "shell.execute_reply.started": "2021-08-02T19:39:03.803086Z",
          "shell.execute_reply": "2021-08-02T19:39:06.385135Z"
        },
        "trusted": true,
        "outputId": "33389504-9e31-49ab-a23f-c8445a84eeaa"
      },
      "source": [
        "# model evaluation\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 8ms/step - loss: 3.0150 - accuracy: 0.6290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNZIOmjeY9bC"
      },
      "source": [
        "Accuracy of the model can be increased by changing hyperparamers and adding data augmentation.\n",
        "<!--  -->"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y9TENGniSlY",
        "execution": {
          "iopub.status.busy": "2021-08-02T19:39:23.155296Z",
          "iopub.execute_input": "2021-08-02T19:39:23.155641Z",
          "iopub.status.idle": "2021-08-02T19:39:23.180089Z",
          "shell.execute_reply.started": "2021-08-02T19:39:23.155610Z",
          "shell.execute_reply": "2021-08-02T19:39:23.179342Z"
        },
        "trusted": true,
        "outputId": "ad36c2fc-a1d2-49bd-b847-647b7cda9dd7"
      },
      "source": [
        "# summary of the model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_2 (Sequential)    (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_39 (Conv2D)           (None, 32, 32, 32)        2432      \n",
            "_________________________________________________________________\n",
            "batch_normalization_33 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_40 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 16, 16, 128)       36992     \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 16, 16, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_34 (Batc (None, 16, 16, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 8, 8, 256)         295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_35 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_44 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_36 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "dropout_29 (Dropout)         (None, 8, 8, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_45 (Conv2D)           (None, 8, 8, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_37 (Batc (None, 8, 8, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "batch_normalization_38 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_30 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_39 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_40 (Batc (None, 4, 4, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_41 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_42 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 2, 2, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_51 (Conv2D)           (None, 2, 2, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_43 (Batc (None, 2, 2, 512)         2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_19 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_35 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               51300     \n",
            "=================================================================\n",
            "Total params: 14,980,740\n",
            "Trainable params: 14,972,740\n",
            "Non-trainable params: 8,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk_soAe18CCT"
      },
      "source": [
        "## **Prediction**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX6_yh3Hjzpv",
        "execution": {
          "iopub.status.busy": "2021-08-02T19:41:32.224078Z",
          "iopub.execute_input": "2021-08-02T19:41:32.224496Z",
          "iopub.status.idle": "2021-08-02T19:41:32.475207Z",
          "shell.execute_reply.started": "2021-08-02T19:41:32.224460Z",
          "shell.execute_reply": "2021-08-02T19:41:32.474272Z"
        },
        "trusted": true,
        "outputId": "ecaa9d91-17d5-498d-b793-22ef2345a1fd"
      },
      "source": [
        "# random image for prediction\n",
        "test_index = np.random.randint(0,10000)\n",
        "plt.imshow(x_test[test_index])\n",
        "labels[int(y_test[test_index])]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'trout'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2Xjd7qnj49x",
        "execution": {
          "iopub.status.busy": "2021-08-02T19:41:43.507006Z",
          "iopub.execute_input": "2021-08-02T19:41:43.507495Z",
          "iopub.status.idle": "2021-08-02T19:41:45.392173Z",
          "shell.execute_reply.started": "2021-08-02T19:41:43.507448Z",
          "shell.execute_reply": "2021-08-02T19:41:45.390682Z"
        },
        "trusted": true,
        "outputId": "b56076da-11f3-41a3-f3ac-604239803337"
      },
      "source": [
        "# prediction\n",
        "pred = model.predict(x_test)\n",
        "# print(pred[test_index])\n",
        "print('\\npredicted label:',labels[np.argmax(pred[test_index])])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "predicted label: trout\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}